{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\diag}[1]{\\text{diag}\\left(#1\\right)}$\n",
    "\n",
    "# A simple numerical example on simulated data\n",
    "\n",
    "## Simulating needed data\n",
    "\n",
    "For now, I assume production functions are Cobb-Douglass, households have Cobb-Douglas preferences over final consumption goods, and the matching function is Cobb-Douglas. In principle, we don't need to be so restrictive about the functional forms of production and matching. Instead all of the relevant information about production technologies is captured by the levels and changes of the elasticities outline below. Any two production functions with the same elasticities and changes in elasticities would generate the same responses to shocks.\n",
    "\n",
    "For each sector $j$, we need the elasticity of production of good $j$ with respect to the intermediate input from each other sector $i$, $\\varepsilon^{f_j}_{x_{ji}}$, and the elasticity of production with respect to the labor input $N_j$, $\\varepsilon^{f_j}_{N_{j}}$. I sample elasticites of production on the unit simplex using an exponential transformation of the normal distribution. To start, for each industry, draw\n",
    "\\begin{align*}\n",
    "    \\left(z_{j1}, \\cdots,z_{jJ},z_{N_j}\\right) \\sim N\\left(\\mu,\\Sigma\\right)\n",
    "\\end{align*}\n",
    "Then define\n",
    "\\begin{align*}\n",
    "    \\varepsilon^{f_j}_{x_{j1}} = \\frac{e^{z_{j1}}}{e^{z_{N_j}}+\\sum_{k=1}^{J}e^{z_{jk}}}\n",
    "\\end{align*}\n",
    "And equivalently for all other sectors. We also need the elasticities of demand with respect to sector $j$'s output, $\\varepsilon^{\\mathcal{D}}_{c_j}$. Notice that we can treat the final demand as another production sector that uses no labor input. We can sample the demand elasticities using the same procedure outlined above.\n",
    "\n",
    "Finally, I sample the matching elasticity with respect to vacancies from a uniform distribution on $[0,1]$. \n",
    "\n",
    "We let $\\Omega$ be the matrix of input elasticities for each sector and $I-\\Psi$ be the Leontif inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of network\n",
    "J = 4 \n",
    "\n",
    "# Sampling input-output matrix entries \n",
    "μ = np.zeros(J+1)\n",
    "Σ = np.eye(J+1)\n",
    "z_draws = np.random.multivariate_normal(μ, Σ, J+1)\n",
    "elasticity_draws = np.exp(z_draws)/np.sum(np.exp(z_draws),1).reshape((J+1,1))\n",
    "\n",
    "# Elasticities\n",
    "epsD = elasticity_draws[0,:-1]/np.sum(elasticity_draws[0,:-1])\n",
    "epsD = epsD.reshape(J,1)\n",
    "Omega = elasticity_draws[1:,:-1]\n",
    "Psi = np.linalg.inv(np.eye(J)-Omega)\n",
    "epsN = np.diag(elasticity_draws[1:,-1])\n",
    "\n",
    "# Drawing elasticity of matching function wrt to U\n",
    "ν = np.random.uniform(size=J)\n",
    "curlyQ = np.diag(-ν)\n",
    "curlyF =  np.eye(J) + curlyQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need recruiter producer ratios $\\tau_j(\\theta_j)$ in each sector. Landais, Michaillat, and Saez (2018) find that the share of recruiters in the US workforce averages around 2.3 percent. I sample recruiter producer ratios uniformly on the interval $[0,0.046]$ to roughly match this fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00702316, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.03911299, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.00296468, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00548014]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = np.diag(np.random.uniform(low=0,high=0.046,size=J))\n",
    "tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining shocks\n",
    "We are interested in the response of sector level and aggregate output and employment to technology shocks $d\\log\\bm{A}$ and labor force shocks $d\\log \\bm{H}$. The code below defines the shocks we feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technology shocks\n",
    "dlog_A = 0.01*np.ones(J)\n",
    "dlog_H = 0.01*np.zeros(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining how wages adjust\n",
    "Since there are mutual gains from trade once an unemployed worker and a firm meet, wages are not pinned down uniquely in models featuring search and matching frictions in the labor market. We must therefore impose a wage schedule, an assumption about how wages change in response to fundamentals, in order to close the model. \n",
    "\n",
    "Let $W_i$ be the nominal sector wage and $w_i = W_i / P_i$ the wage for sector i adjusted for goods price in that sector. \n",
    "\n",
    "In particular, we need to specify the elasticity of wages to technology shocks and labor force shocks in each sector, $\\left\\{\\left\\{\\varepsilon^{w_j}_{A_{ji}},\\varepsilon^{w_j}_{H_{ji}}\\right\\}_{i=1}^{J}\\right\\}_{j=1}^{J}$. For instance, a simple, but unrealistic, assumption is that wages respond positively to own sector productivity and negatively to own sector labor force, but do not respond to changes in other sectors. In general, we express changes in wages as a function of changes in productivity and the labor force. \n",
    "\\begin{align}\n",
    "    d\\log \\bm{w} &= \\bm{\\Lambda_{A}} d\\log \\bm{A} + \\bm{\\Lambda_{H}} d\\log \\bm{H} \\tag{1}\n",
    "\\end{align}\n",
    "Where $\\bm{\\Lambda_{A}}$ contains wage elasticities to productivity changes and $\\bm{\\Lambda_{H}}$ contains wage elasticities to labor force changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.87443321, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 6.50910543, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 4.30854721, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 4.51898069]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wage elasticities\n",
    "epsW_A = np.diag(np.random.uniform(low=3,high=7,size=J))\n",
    "epsW_H = np.diag(np.random.uniform(low=-2,high=0,size=J))\n",
    "epsW_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the log change in wages\n",
    "def WageFunc(dlog_A, dlog_H, epsW_A, epsW_H):\n",
    "    dlog_wR = epsW_A @ dlog_A + epsW_H @ dlog_H\n",
    "    return dlog_wR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03874433, 0.06509105, 0.04308547, 0.04518981])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How wages change\n",
    "dlog_wR = WageFunc(dlog_A, dlog_H, epsW_A, epsW_H)\n",
    "dlog_wR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tightness propagation\n",
    "We with wage changes in hand, we solve for first order changes in tightness in terms of $d\\log\\bm{A}$, $d\\log\\bm{H}$, and $d\\log\\bm{w}$. The general formula for changes in tightness, treating sector 1 prices as the numeraire, is\n",
    "\\begin{align}\n",
    "    d \\log \\bm{\\theta} &=\\left(\\diag{\\bm{\\mathcal{F}}}-\\bm{\\Xi_{\\theta}}\\right)^{-1}\\left(\\left(\\bm{I} - \\bm{\\Psi} \\diag{\\bm{\\varepsilon^f_N}}\\right) \\left(d\\log \\bm{\\varepsilon^f_N} + d\\log \\bm{\\lambda} - d\\log \\bm{H}\\right) + \\bm{\\Psi} d\\log \\bm{A}\\right) \\\\\n",
    "    &- \\left(\\diag{\\bm{\\mathcal{F}}}-\\bm{\\Xi_{\\theta}}\\right)^{-1} \\left(d\\log \\bm{w}-d\\log\\bm{p}\\right) \\tag{2}\n",
    "\\end{align}\n",
    "Where \n",
    "\\begin{align*}\n",
    "    \\bm{\\Xi_\\theta} = \\bm{\\Psi}\\diag{\\bm{\\varepsilon^f_N}}\\left(\\diag{\\bm{\\mathcal{F}}} + \\diag{\\bm{\\tau}}\\diag{\\bm{\\varepsilon^{\\mathcal{Q}}_{\\theta}}}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ThetaFunc(dlog_A, dlog_H, dlog_wR, dlog_epsN, dlog_lam, Psi, curlyF, curlyQ, epsN, tau, num=0):\n",
    "    \n",
    "    # Creating matrices\n",
    "    Xi_a = Psi\n",
    "\n",
    "    Xi_theta = Psi @ epsN @ curlyF+ Psi @ epsN @ tau @ curlyQ\n",
    "    #Xi_theta[num,:] = Xi_theta[num,:] + Psi[num,:] @ epsN @ tau @ curlyQ\n",
    "\n",
    "    Xi_w = np.zeros_like(Psi)\n",
    "\n",
    "    I = np.eye(Psi.shape[0])\n",
    "\n",
    "    # Contribution of different components\n",
    "    Cw = np.linalg.inv(curlyF - Xi_theta) @ (I - Xi_w)\n",
    "    Ca = np.linalg.inv(curlyF - Xi_theta) @ Xi_a \n",
    "    Ch = np.linalg.inv(curlyF - Xi_theta) @ (I - Psi @ epsN)\n",
    "\n",
    "    # Change in tightness\n",
    "    dlog_theta = Ch @ (dlog_epsN + dlog_lam - dlog_H) + Ca @ dlog_A - Cw @ dlog_wR\n",
    "\n",
    "    return dlog_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming Cobb-Douglas production implies $d\\log\\bm{\\varepsilon^f_N} = d\\log \\bm{\\lambda} = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.74100498, -1.25744435, -0.58669409, -0.50319454])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_epsN = np.zeros_like(dlog_A)\n",
    "dlog_lam = np.zeros_like(dlog_A)\n",
    "dlog_theta = ThetaFunc(dlog_A, dlog_H, dlog_wR, dlog_epsN, dlog_lam, Psi, curlyF, curlyQ, epsN, tau, num=1)\n",
    "dlog_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price and output propagation\n",
    "With changes in tightness in hand, we can now work out how prices and sectoral production changes in response to technology and labor force shocks. Price changes are given by \n",
    "\\begin{align}\n",
    "    \\left(I - \\Psi\\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right)\\right)d \\log \\bm{p} &=\\bm{\\Psi} \\left(\n",
    "        \\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right) \\left(d\\log\\bm{w}  - d\\log\\bm{p}\\right) -\\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right)\\text{diag}\\left(\\bm{\\tau}\\right)\\text{diag}\\left(\\bm{\\varepsilon^{\\mathcal{Q}}_{\\theta}}\\right)d\\log\\bm{\\theta} - d\\log \\bm{A} \\right) \\tag{3}\n",
    "\\end{align}\n",
    "While $\\Xi = \\left(I - \\Psi\\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right)\\right)$ is not invertible, we impose an additional restrction $d\\log p_i = 0$, with the good produced by sector $i$ the numeraire good of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PriceFunc(dlog_A, dlog_wR, dlog_theta, Psi, curlyQ, epsN, tau, num=0):\n",
    "    # Contributions of different components\n",
    "    Cw = Psi @ epsN \n",
    "    Cw[num, :] = 0\n",
    "    Ct = Psi @ epsN @ tau @ curlyQ\n",
    "    Ct[num, :] = 0\n",
    "    Ca = np.copy(Psi)\n",
    "    Ca[num, :] = 0\n",
    "    \n",
    "    Xi = np.eye(Psi.shape[0]) - Psi @ epsN \n",
    "    Xi[num, :] = 0\n",
    "    Xi[num, num] = 1\n",
    "\n",
    "    # Price changes\n",
    "    dlog_p = np.linalg.inv(Xi) @ (Cw @ dlog_wR - Ct @ dlog_theta - Ca @dlog_A)\n",
    "    return dlog_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0120913 ,  0.        , -0.01477692, -0.00527658])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 1\n",
    "dlog_p = PriceFunc(dlog_A, dlog_wR, dlog_theta, Psi, curlyQ, epsN, tau, num)\n",
    "dlog_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can solve explicitly for $d\\log\\bm{p}$ \n",
    "\\begin{align*}\n",
    "    d\\log \\bm{p} &= \\bm{\\Xi_p}^{-1}\\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right) \\left(d\\log\\bm{w} - d\\log \\bm{p}\\right)\\nonumber \\\\\n",
    "    &-\\bm{\\Xi_p}^{-1}\\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right)\\text{diag}\\left(\\bm{\\tau}\\right)\\text{diag}\\left(\\bm{\\varepsilon^{\\mathcal{Q}}_{\\theta}}\\right)d\\log\\bm{\\theta}\\\\\n",
    "    &- \\bm{\\Xi_p}^{-1} d\\log \\bm{A}\n",
    "\\end{align*}\n",
    "Where\n",
    "\\begin{align*}\n",
    "    \\bm{\\Xi_{p}} &= \\begin{bmatrix}\n",
    "        0 & \\bm{0}_{1\\times (J-1)} \\\\\n",
    "        \\bm{0}_{(J-1)\\times 1} & \\bm{I}_{(J-1) \\times (J-1)} - \\diag{\\bm{\\varepsilon^f_N}\\setminus\\varepsilon^{f_1}_{N_1}}\n",
    "    \\end{bmatrix} - \\bm{\\Omega}\n",
    "\\end{align*}\n",
    "The two solution methods should coincide to machine precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PriceFunc2(dlog_A, dlog_wR, dlog_theta, Omega, curlyQ, epsN, tau, num = 0):\n",
    "    Xi_p = np.eye(Omega.shape[0]) - epsN \n",
    "    Xi_p[num, : ] = 0 \n",
    "    Xi_p = Xi_p - Omega\n",
    "    dlog_p = np.linalg.inv(Xi_p) @ (epsN @ (dlog_wR - tau @ curlyQ @ dlog_theta) - dlog_A)\n",
    "    return dlog_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.20912963e-02, -4.49293380e-16, -1.47769246e-02, -5.27658099e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_p2 = PriceFunc2(dlog_A, dlog_wR, dlog_theta, Omega, curlyQ, epsN, tau, num)\n",
    "dlog_p2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that our solution is consistent with $p_i$ being the numeraire by checking that \n",
    "\\begin{align*}\n",
    "    0 & = \\varepsilon^{f_i}_{N_i} \\left( d\\log w_i - d\\log p_i - \\tau_i(\\theta_i) \\varepsilon^{\\mathcal{Q_i}}_{\\theta_i} d\\log \\theta_i\\right)+\\Omega_i d\\log\\bm{p} - d\\log A_i \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.087671619437458e-15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsN[num,num] * (dlog_wR[num] - tau[num,num] * curlyQ[num,num] * dlog_theta[num]) + Omega[num,] @ dlog_p - dlog_A[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsN[num,num] * (dlog_wR[num] - tau[num,num] * curlyQ[num,num] * dlog_theta[num]) + Omega[num,] @ dlog_p2 - dlog_A[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check that our two solution methods coincide, providing another sanity check on our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.74086309e-16, 1.42420797e-15, 1.38300829e-15, 1.38430933e-15])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_p - dlog_p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And output changes are given by\n",
    "\\begin{align}\n",
    "    d\\log \\bm{y} &= \\bm{\\Psi}\\left(d\\log\\bm{A} + \\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right)\\left(\\text{diag}\\left(\\bm{\\mathcal{F}}\\right)+\\text{diag}\\left(\\bm{\\tau}\\right)\\text{diag}\\left(\\bm{\\varepsilon^{\\mathcal{Q}}_{\\theta}}\\right)\\right)d\\log \\bm{\\theta} + \\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right) d\\log\\bm{H}\\right) \\nonumber\\\\\n",
    "    &-\\bm{\\Psi} \\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right) d\\log \\bm{\\varepsilon^{f}_{N}} + \\left(\\bm{I} - \\bm{\\Psi}\\text{diag}\\left(\\bm{\\varepsilon^{f}_{N}}\\right)\\right) d\\log \\bm{\\lambda} \\tag{4}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OutputFunc(dlog_A, dlog_H, dlog_theta, dlog_epsN, dlog_lam, Psi, curlyQ, curlyF, epsN, tau):\n",
    "    # Contributions of different coponents\n",
    "    Ca = Psi\n",
    "    Ct = Psi @ epsN @ (curlyF + tau @ curlyQ) \n",
    "    Ch = Psi @ epsN \n",
    "    I = np.eye(Psi.shape[0])\n",
    "\n",
    "    # Changes in output\n",
    "    dlog_y = Ca @ dlog_A + Ct @ dlog_theta + Ch @ (dlog_H-dlog_epsN) + (I - Ch) @ dlog_lam \n",
    "\n",
    "    return dlog_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32540216, -0.33749345, -0.32271653, -0.33221687])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_y = OutputFunc(dlog_A, dlog_H, dlog_theta, dlog_epsN, dlog_lam, Psi, curlyQ, curlyF, epsN, tau)\n",
    "dlog_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Cobb-Douglas production, real output should change by the same amount in each sector. This provides an overall check of our code given the Cobb-Douglas assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32540216, -0.32540216, -0.32540216, -0.32540216])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change in nominal GDP\n",
    "dlog_p + dlog_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check consistency. We should get the same change in labor by either calculating the change in labor supply\n",
    "\\begin{align}\n",
    "    d\\log \\bm{L^s} = \\text{diag}\\left(\\mathcal{F}\\right) d\\log \\bm{\\theta} + d\\log \\bm{H} \\tag{5}\n",
    "\\end{align}\n",
    "Or the change in labor demand\n",
    "\\begin{align}\n",
    "    d\\log \\bm{L^d} = d\\log \\bm{\\varepsilon^{f}_N} + d\\log \\bm{p} + d\\log\\bm{y} - d\\log\\bm{w} \\tag{6}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaborSupply(dlog_H,dlog_theta,curlyF):\n",
    "    dlog_Ls = curlyF @ dlog_theta + dlog_H\n",
    "    return dlog_Ls\n",
    "    \n",
    "def LaborDemand(dlog_wR, dlog_y, dlog_epsN):\n",
    "    dlog_Ld = dlog_epsN  + dlog_y - dlog_wR\n",
    "    return dlog_Ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistency requires\n",
    "\\begin{align*}\n",
    "    d\\log \\bm{L^d} - d\\log\\bm{L^s} = 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.66533454e-16,  0.00000000e+00, -5.55111512e-17, -1.11022302e-16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaborDemand(dlog_wR, dlog_y, dlog_epsN) - LaborSupply(dlog_H,dlog_theta,curlyF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment\n",
    "We can use changes in tightness and the labor force to calculate changes in employment. \n",
    "\\begin{align}\n",
    "    d\\log \\bm{L} = \\text{diag}\\left(\\mathcal{F}\\right) d\\log \\bm{\\theta} + d\\log \\bm{H} \\tag{5}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36414649, -0.40258451, -0.365802  , -0.37740668])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_L = LaborSupply(dlog_H,dlog_theta,curlyF)\n",
    "dlog_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unemployment in sector $j$ is $U_j = H_j - L_j$. The log change in Unemployment is \n",
    "\\begin{align}\n",
    "    d\\log \\bm{U} = \\diag{\\bm{U}}^{-1}\\left(\\diag{\\bm{H}} d\\log \\bm{H} - \\diag{L}d\\log\\bm{L}\\right)\\tag{6}\n",
    "\\end{align}\n",
    "The unemployment rate in sector $j$ is $u_j = \\frac{H_j-L_j}{H_j}$. The log change in the unemployment rate is \n",
    "\\begin{align}\n",
    "    d\\log \\bm{u} = \\left(\\bm{I} - \\diag{\\bm{u}}\\right)\\diag{\\bm{u}}^{-1} \\left(d\\log\\bm{H} - d\\log\\bm{L}\\right) \\tag{7}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnemploymentFunc(dlog_H, dlog_L, U, H, L):\n",
    "    dlog_U = np.linalg.inv(U) @ (H @ dlog_H - L @ dlog_L)\n",
    "    return dlog_U\n",
    "\n",
    "def UnRateFunc(dlog_H, dlog_L, u):\n",
    "    dlog_u = (np.eye(dlog_H.shape[0]) - u) @ np.linalg.inv(u) @ (dlog_H - dlog_L)\n",
    "    return dlog_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "Given first order changes in output, we can use the elasticities of demand and changes in domar weights calculate changes in aggregate output.\n",
    "\\begin{align}\n",
    "    d\\log Y = \\bm{\\varepsilon^{\\mathcal{D}}_{c}}' \\left(d\\log\\bm{\\varepsilon^{\\mathcal{D}}_{c}} + d\\log \\bm{y} - d\\log \\bm{\\lambda}\\right) \\tag{8}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggOutputFunc(dlog_y, dlog_epsD, dlog_lam, epsD):\n",
    "    dlog_Y = epsD.T @ (dlog_epsD + dlog_y - dlog_lam)\n",
    "    return dlog_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming Cobb-Douglas, $d\\log \\bm{\\varepsilon^{\\mathcal{D}}_{c}} = d\\log \\bm{\\lambda} = \\bm{0}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33083624])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_epsD = np.zeros_like(dlog_A)\n",
    "dlog_Y = AggOutputFunc(dlog_y, dlog_epsD, dlog_lam, epsD)\n",
    "dlog_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbfaa7553469519299698c7576cfa5da0b434ea4638d3b56a3f047f0de3b7cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
