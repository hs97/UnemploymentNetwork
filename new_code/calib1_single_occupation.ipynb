{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions.multi_occupation_network as multi_occupation_network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Excersize 1: Single Occupation\n",
    "\n",
    "Suppose there is just one type of labor, in other words that $\\mathcal{O}=1$. We calibrate our model to mathc BEA input-output tables, and treat the residual, the part of production not accounted for by intermediate inputs, as the labor elasticity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/clean/'\n",
    "dfA      = pd.read_csv(data_dir + 'A.csv')\n",
    "dfParam  = pd.read_csv(data_dir + 'params.csv')\n",
    "dfLshare = pd.read_csv(data_dir + 'labor_share.csv')\n",
    "dfLabor_market_yearly= pd.read_csv(data_dir + 'labor_market_yearly.csv')\n",
    "dfLabor_market_yearly = dfLabor_market_yearly.sort_values(by=['year', 'BEA_sector'])\n",
    "dfLabor_market_yearly = dfLabor_market_yearly.dropna(axis=0)\n",
    "dfLabor_market_yearly = dfLabor_market_yearly[dfLabor_market_yearly['year'] == 2005]\n",
    "# reformatting parameters\n",
    "Omega = np.array(dfA.iloc[:, 1:], dtype='float64')\n",
    "Psi = np.linalg.inv(np.eye(Omega.shape[0])-Omega)\n",
    "J = Omega.shape[0]\n",
    "O = 1\n",
    "\n",
    "epsN = np.array(dfParam.α).reshape((J,O))\n",
    "epsD = np.array(dfParam.θ_alt).reshape((J,1))\n",
    "\n",
    "# labor market stats\n",
    "θ = dfLabor_market_yearly['v'].sum() / dfLabor_market_yearly['u'].sum() \n",
    "ν = np.ones(O) * 0.5\n",
    "curlyQ = np.diag(-ν)\n",
    "curlyF =  np.eye(O) + curlyQ\n",
    "r = 0.0282\n",
    "curlyT = np.diag(r / (θ**(-ν) - r))\n",
    "# NOTE: here I am picking the r so the τ's roughly look right. Down the line, we can calibrate τ directly from the data. \n",
    "# Also note that tightness is computed from unemployed workers, but in our model it should be computed from the whole work force.\n",
    "\n",
    "curlyL = np.array(dfLabor_market_yearly['e']/dfLabor_market_yearly['e'].sum()).reshape((O,J))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the shocks we are interested in to allow us to easily change these in the future, that is we define the vectors $d\\log\\bm{A}$ and $d\\log\\bm{H}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlog_A = np.zeros((J, 1))\n",
    "dlog_A[3] = 0.01 \n",
    "dlog_H = np.zeros((O,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume Cobb-Douglas production and preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlog_lam = np.zeros_like(dlog_A)\n",
    "dlog_epsN = np.zeros_like(epsN)\n",
    "dlog_epsD = np.zeros_like(epsD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to make some assumption about how wages change. We begin by assuming that wages net of sectoral employment weighted prices do not change in response to changes in either productivity or the labor force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10656133, 0.02306299, 0.08647666, 0.36979604, 0.02282295,\n",
       "        0.21167203, 0.17416404, 0.11105386, 0.07859807, 0.11266754,\n",
       "        0.32066736, 0.06687355, 0.45518659, 0.15413244, 0.11495578,\n",
       "        0.07581048, 0.05211025]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#epsW_A = np.zeros((O,J))\n",
    "gamma_A = 1\n",
    "gamma_H = 1\n",
    "epsW_A, epsW_H = multi_occupation_network.WageElasticityFunc(gamma_A, gamma_H, Psi, curlyL, epsN)\n",
    "epsW_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlog_wR = multi_occupation_network.WageFunc(dlog_A, dlog_H, epsW_A, epsW_H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these pieces in hand, we can now estimate responses to tightness. For details, see the multiple occupations example code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.55111512e-17]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curlyE = multi_occupation_network.curlyEFunc(dlog_epsN,epsN)\n",
    "dlog_theta = multi_occupation_network.ThetaFunc(dlog_A, dlog_H, dlog_wR, dlog_epsN, dlog_lam, Psi, Omega, curlyF, curlyQ, curlyT, curlyE, curlyL, epsN)\n",
    "dlog_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00],\n",
       "       [ 1.51291126e-05],\n",
       "       [-6.33827206e-03],\n",
       "       [-1.95856091e-02],\n",
       "       [ 2.42313346e-04],\n",
       "       [ 8.66557770e-04],\n",
       "       [-1.18828419e-04],\n",
       "       [-8.50104220e-05],\n",
       "       [-1.12048795e-03],\n",
       "       [-2.78191602e-03],\n",
       "       [-2.60782739e-03],\n",
       "       [-9.30805219e-04],\n",
       "       [ 1.69910558e-04],\n",
       "       [-1.10237000e-03],\n",
       "       [ 2.60390345e-04],\n",
       "       [-6.19598947e-04],\n",
       "       [ 3.98151742e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "dlog_p = multi_occupation_network.PriceFunc(dlog_A, dlog_wR, dlog_theta, Psi, curlyQ, epsN, curlyT, curlyL, num=num)\n",
    "dlog_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00189839],\n",
       "       [0.00188326],\n",
       "       [0.00823666],\n",
       "       [0.021484  ],\n",
       "       [0.00165608],\n",
       "       [0.00103183],\n",
       "       [0.00201722],\n",
       "       [0.0019834 ],\n",
       "       [0.00301888],\n",
       "       [0.00468031],\n",
       "       [0.00450622],\n",
       "       [0.0028292 ],\n",
       "       [0.00172848],\n",
       "       [0.00300076],\n",
       "       [0.001638  ],\n",
       "       [0.00251799],\n",
       "       [0.00150024]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_y = multi_occupation_network.OutputFunc(dlog_A,dlog_H, dlog_theta, dlog_lam, Psi, Omega, curlyQ, curlyF, epsN, curlyT, curlyE)\n",
    "dlog_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check labor market clearing holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.67361738e-19]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_occupation_network.LaborSupply(dlog_H, dlog_theta, curlyF) - multi_occupation_network.LaborDemand(dlog_wR, dlog_y, dlog_p, dlog_epsN, curlyL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate changes in aggregate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00717491]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_aggY = multi_occupation_network.AggOutputFunc(dlog_y, dlog_lam, dlog_epsD, epsD)\n",
    "dlog_aggY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since labor market frictions are the only source of inefficiency in our network economy, in the absence of labor market frictions our network economy is fully efficient. It is well known that Hulten's theorem holds in efficient network economies with Cobb-Douglas technology. We can therefore easily compare the implications of labor market frictions for aggregate output with the implications of the same technology shocks absent labor market frictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00717491]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsD.T @ Psi @ dlog_A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare sector level output changes with and without labor market frictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
